{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996bd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbcc4b",
   "metadata": {},
   "source": [
    "# Translator: JSON to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4721dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to iSeeOntoAPI to get the most similar cases\n",
    "def get_cases_json_from_api(treeId_paremeter,usecaseId_parameter,topK_paremeter):\n",
    "    \"\"\"\n",
    "        Function to get the solutions for that case in json format\n",
    "    \"\"\"\n",
    "    url = \"https://api-dev.isee4xai.com/api/trees/cbr_retrieve\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "      \"treeId\": treeId_paremeter,\n",
    "      \"usecaseId\": usecaseId_parameter,\n",
    "      \"topk\": topK_paremeter\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    #print(response.text)\n",
    "\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the node list from the behavior tree for the graph structure\n",
    "def print_node_instances(node_id, nodes_dict, node_list, id_list): \n",
    "    node = nodes_dict[node_id]\n",
    "    node_instance = node['Instance']\n",
    "    if node_instance is None:\n",
    "        return None\n",
    "    node_list.append(node_instance)\n",
    "    id_list.append(node_id)\n",
    "\n",
    "    if 'firstChild' in node:\n",
    "        first_child_id = node['firstChild']['Id']\n",
    "        print_node_instances(first_child_id, nodes_dict, node_list, id_list)\n",
    "        next_child = node['firstChild'].get('Next')\n",
    "\n",
    "        while next_child is not None:\n",
    "            next_child_id = next_child['Id']\n",
    "            print_node_instances(next_child_id, nodes_dict, node_list, id_list)\n",
    "            next_child = next_child.get('Next')\n",
    "\n",
    "    return node_list, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a931ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the parent in the behavior tree\n",
    "def get_index(node_id, nodes_dict, id_list):\n",
    "    node = nodes_dict[node_id]\n",
    "    node_instance = node.get('Instance')\n",
    "    node_index = id_list.index(node_id)\n",
    "    node_index = node_index + 1\n",
    "\n",
    "    return node_index, node_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c2f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the parent of a node\n",
    "def find_parent(node_id, node, parent_child_dict, id_list, nodes_dict):\n",
    "    parent_index, parent_instance = get_index(node_id, nodes_dict, id_list)\n",
    "    \n",
    "    if 'firstChild' in node:\n",
    "        first_child_id = node['firstChild']['Id']\n",
    "        child_index, child_instance = get_index(first_child_id, nodes_dict, id_list)\n",
    "\n",
    "        if parent_index not in parent_child_dict:\n",
    "            parent_child_dict[parent_index] = []\n",
    "        if child_index not in parent_child_dict[parent_index]:\n",
    "            parent_child_dict[parent_index].append(child_index)\n",
    "        \n",
    "        next_child = node['firstChild'].get('Next')\n",
    "        while next_child is not None:\n",
    "            next_child_id = next_child['Id']\n",
    "            child_index, child_instance = get_index(next_child_id, nodes_dict, id_list)\n",
    "            if child_index not in parent_child_dict[parent_index]:\n",
    "                parent_child_dict[parent_index].append(child_index)  # Add child index to the parent's list\n",
    "            next_child = next_child.get('Next')\n",
    "\n",
    "        return parent_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4fb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parent-child dictionary\n",
    "def create_parent_child_dict(nodes_dict, node_list, id_list): \n",
    "    parent_child_dict = {}   \n",
    "    # root = node_list[0] #r \n",
    "    parent_child_dict[0] = [1]  # Add root node with index 0\n",
    "\n",
    "    for i, (instance, node_id) in enumerate(zip(node_list[1:], id_list), start=1):\n",
    "        node_index = i\n",
    "        node_id =id_list[node_index-1]\n",
    "        node = nodes_dict[node_id]\n",
    "        find_parent(node_id, node, parent_child_dict, id_list, nodes_dict)\n",
    "    \n",
    "    return parent_child_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba15fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the adjacency list\n",
    "def build_adjacency_list(node_list, parent_child_dict): \n",
    "    adjacency_list = [[] for _ in range(len(node_list))]\n",
    "\n",
    "    for node_index, node_instance in enumerate(node_list):\n",
    "        if node_index in parent_child_dict:\n",
    "            children = parent_child_dict[node_index]\n",
    "            adjacency_list[node_index] = children\n",
    "\n",
    "    return adjacency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b9d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to translate the case solution to graph structure \n",
    "# This function must work for all the cases and the query \n",
    "# TODO\n",
    "def translate_cases_from_json_to_graph(case):\n",
    "  tree_dict, nodes_dict, parent_child_dict = {},{},{}\n",
    "  node_list = ['r'] # Added 'r' as the default root node in the node list\n",
    "  id_list =[] #List of node id's \n",
    "         \n",
    "\n",
    "  for idx, obj in enumerate(case, start=1):\n",
    "      trees = obj['data']['trees']\n",
    "      # Get the 'nodes' from 'trees'\n",
    "      for tree in trees:\n",
    "          nodes = tree.get('nodes', {})\n",
    "          nodes_dict.update(nodes)\n",
    "          # Get the root node\n",
    "          root_node_id = tree.get('root')    \n",
    "\n",
    "      # Call the recursive function to print node instances\n",
    "      node_list, id_list= print_node_instances(root_node_id, nodes_dict, node_list = ['r'], id_list =[])\n",
    "      # Call the function to create the parent_child dictionary\n",
    "      parent_child_dict = create_parent_child_dict(nodes_dict, node_list, id_list)\n",
    "      # Build the adjacency list from the behavior tree\n",
    "      adjacency_list = build_adjacency_list(node_list, parent_child_dict)\n",
    "      \n",
    "      tree_key = f'tree_{idx}'\n",
    "    #   tree_dict[tree_key] = trees\n",
    "      tree_dict[tree_key] = {\n",
    "              'tree_json': trees,\n",
    "              'tree_graph': {\n",
    "                  'nodes': node_list,\n",
    "                  'adj': adjacency_list\n",
    "              }\n",
    "      }\n",
    "\n",
    "  return tree_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d89ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tree_1': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict RDR for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/IntegratedGradients'], 'adj': [[1], [2], [3, 4], [], []]}}, 'tree_2': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '2a1e79cf-2ccd-47d7-96a3-768047304a85', 'Instance': 'Explanation Experience', 'description': '', 'root': '89d03d85-d7dd-4dfd-be74-1d992d5bce56', 'properties': {}, 'nodes': {'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c': {'id': 'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 108}, 'firstChild': {'Id': '7e6f46df-dd97-47dd-8c60-9e6d3f479414', 'Next': {'Id': 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b', 'Next': None}}}, '89d03d85-d7dd-4dfd-be74-1d992d5bce56': {'id': '89d03d85-d7dd-4dfd-be74-1d992d5bce56', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 0}, 'firstChild': {'Id': 'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c', 'Next': None}}, '7e6f46df-dd97-47dd-8c60-9e6d3f479414': {'id': '7e6f46df-dd97-47dd-8c60-9e6d3f479414', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -324, 'y': 288}, 'params': {'Question': {'key': 'Question', 'value': 'What patterns contributed to the system prediction?'}}}, 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b': {'id': 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b', 'Concept': 'Variant', 'Instance': 'Variant', 'description': '', 'properties': {}, 'display': {'x': 0, 'y': 264}, 'firstChild': {'Id': '98489712-951e-4685-8883-76c2bcd9e634', 'Next': {'Id': 'fad46100-dcf8-42fe-8244-39e383098d32', 'Next': None}}}, '98489712-951e-4685-8883-76c2bcd9e634': {'id': '98489712-951e-4685-8883-76c2bcd9e634', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': -132, 'y': 372}, 'params': {'target_class': {'key': 'target_class', 'value': None, 'default': None, 'range': [None, None], 'required': 'false', 'description': 'Integer denoting the desired class for the computation of the attributions. Ignore for regression models. Defaults to the predicted class of the instance.', 'type': 'number'}, 'method': {'key': 'method', 'value': 'gausslegendre', 'default': 'gausslegendre', 'range': ['gausslegendre', 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid'], 'required': 'false', 'description': \"Method for the integral approximation. The methods available are: 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid', 'gausslegendre'. Defaults to 'gausslegendre'.\", 'type': 'select'}, 'n_steps': {'key': 'n_steps', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Number of step in the path integral approximation from the baseline to the input instance. Defaults to 10.', 'type': 'number'}, 'internal_batch_size': {'key': 'internal_batch_size', 'value': 100, 'default': 100, 'range': [None, None], 'required': 'false', 'description': 'Batch size for the internal batching. Defaults to 100.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1200, 'default': 1200, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 600, 'default': 600, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}, 'fad46100-dcf8-42fe-8244-39e383098d32': {'id': 'fad46100-dcf8-42fe-8244-39e383098d32', 'Concept': 'Explanation Method', 'Instance': '/Images/NearestNeighbours', 'description': '', 'properties': {}, 'display': {'x': 120, 'y': 372}, 'params': {'no_neighbours': {'key': 'no_neighbours', 'value': 3, 'default': 3, 'range': [None, None], 'required': 'false', 'description': 'number of neighbours returned as an integer; default is 3.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1200, 'default': 1200, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 600, 'default': 600, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 720, 'camera_y': 394.5, 'camera_z': 1, 'x': -192, 'y': -108}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', 'Variant', '/Images/IntegratedGradients', '/Images/NearestNeighbours'], 'adj': [[1], [2], [3, 4], [], [5, 6], [], []]}}, 'tree_3': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict category Y for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/IntegratedGradients'], 'adj': [[1], [2], [3, 4], [], []]}}, 'tree_4': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict category Y for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/GradCamTorch', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/GradCamTorch'], 'adj': [[1], [2], [3, 4], [], []]}}, 'tree_5': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict category Y not Z for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/GradCamTorch', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/GradCamTorch'], 'adj': [[1], [2], [3, 4], [], []]}}}\n"
     ]
    }
   ],
   "source": [
    "# Translate each BT in JSON format to graph structure with a list of nodes and adjacency.\n",
    "treeId_parameter = \"64b676baa737e466ce27f166\" # query\n",
    "usecaseId_parameter = \"6426a68da3402ba28c44a7c0\" # case of the query\n",
    "topK_parameter = 5\n",
    "\n",
    "cases_json = get_cases_json_from_api(treeId_parameter,usecaseId_parameter,topK_parameter)\n",
    "json_to_graph_dict = translate_cases_from_json_to_graph(cases_json) \n",
    "\n",
    "print(json_to_graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12546dd",
   "metadata": {},
   "source": [
    "# Translator with filtering critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60abfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to get the explainers list\n",
    "def get_explainer_list():\n",
    "    \n",
    "    # explainer API\n",
    "    url = \"https://api-onto-dev.isee4xai.com/api/explainers/list\"\n",
    "\n",
    "    payload={}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49be2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to get the explainer fields\n",
    "def get_explainer_fields():\n",
    "    \n",
    "    # explainer fields API\n",
    "    url = \"https://api-onto-dev.isee4xai.com/api/onto/cockpit/ExplainerFields\"\n",
    "\n",
    "    payload={}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a6d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the children from the properties\n",
    "def extract_children_data(list):\n",
    "    children_data = {}\n",
    "    for child in list['children']:\n",
    "        child_key = child['key']\n",
    "        child_label = child['label']\n",
    "        children_data[child_key] = child_label\n",
    "        children_data.update(extract_children_data(child))\n",
    "    return children_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977edd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the property values from the explainer fields\n",
    "def get_properties(explainer_fields):\n",
    "    children_dict, properties_dict = {}, {}\n",
    "    for field in explainer_fields:\n",
    "        field_structure = ['ExplainabilityTechnique', 'Explanation', 'InformationContentEntity', 'AIMethod', 'AITask']\n",
    "        type_list = explainer_fields[field]\n",
    "        if field in field_structure:\n",
    "            children_dict = extract_children_data(type_list)\n",
    "            properties_dict[field] = children_dict\n",
    "        else:\n",
    "            type_mapping = {entry[\"key\"]: entry[\"label\"] for entry in type_list}\n",
    "            properties_dict[field] = type_mapping\n",
    "\n",
    "    return properties_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb58a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the property values that appear in the explainers in our library\n",
    "def filter_properties(exp_properties_dict, filter_properties_dict):\n",
    "    for explainer, properties in exp_properties_dict.items():\n",
    "        for prop, prop_value in properties.items():\n",
    "            if isinstance(prop_value, list): # isinstance() check is performed to identify if the value is a list. \n",
    "                filter_properties_dict.setdefault(prop, set()).update(prop_value) # update() method is used to add all elements of the list to the set       \n",
    "            else:\n",
    "                filter_properties_dict.setdefault(prop, set()).add(prop_value)\n",
    "\n",
    "    return filter_properties_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f14bb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset_type\n",
    "def get_dataset_type(exp_properties_dict):\n",
    "    explainer_dataset_type = {}\n",
    "    explainer_dataset_type = {name: properties['dataset_type'] for name, properties in exp_properties_dict.items() if 'dataset_type' in properties}\n",
    "    return explainer_dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb3817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get properties of the explainers from the explainer list\n",
    "def get_explainer_properties(explainer_list):\n",
    "\n",
    "    # Create a dictionary to store the properties\n",
    "    exp_properties_dict = {}\n",
    "\n",
    "    # Extract the properties for each 'name'\n",
    "    for entry in explainer_list:\n",
    "        name = entry['name']\n",
    "        properties = {\n",
    "            'technique': entry['technique'],\n",
    "            'dataset_type': entry['dataset_type'],\n",
    "            'explanation_type': entry['explanation_type'],\n",
    "            'concurrentness': entry['concurrentness'],\n",
    "            'scope': entry['scope'],\n",
    "            'portability': entry['portability'],   \n",
    "            'target': entry['target'],\n",
    "            'presentations': entry['presentations'],\n",
    "            'computational_complexity': entry['computational_complexity'],\n",
    "            'ai_methods': entry['ai_methods'],\n",
    "            'ai_tasks': entry['ai_tasks'],\n",
    "            \"implementation\": entry['implementation'],\n",
    "            # \"metadata\": entry['metadata']\n",
    "        }\n",
    "        exp_properties_dict[name] = properties\n",
    "        \n",
    "    return exp_properties_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be1211c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists out all the explainers that have the marked property values\n",
    "def find_explainers_by_propertyvalues(property_values, exp_properties_dict):\n",
    "    matching_explainers = []\n",
    "    for explainer, properties in exp_properties_dict.items():\n",
    "        satisfies_all_properties = True\n",
    "        for property_name, property_value in property_values.items():\n",
    "            property_satisfied = False\n",
    "            \n",
    "            if properties[property_name] == property_value:\n",
    "                    property_satisfied = True\n",
    "\n",
    "            if not property_satisfied:\n",
    "                satisfies_all_properties = False\n",
    "                break\n",
    "\n",
    "        if satisfies_all_properties:\n",
    "            matching_explainers.append(explainer)\n",
    "            \n",
    "    return matching_explainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f54a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the BTs with the explainers that have the property values marked on the form (comma-separated)\n",
    "def bts_with_critiques(exp_properties_dict, property_values):\n",
    "    \n",
    "    bt_graph_dict = {}\n",
    "    \n",
    "    # Find explainers with the given property value\n",
    "    matching_explainers = find_explainers_by_propertyvalues(property_values, exp_properties_dict)\n",
    "    # example: ['/Images/IntegratedGradients', '/Images/NearestNeighbours']\n",
    "    print(matching_explainers)\n",
    "\n",
    "    for index, tree in json_to_graph_dict.items():\n",
    "        if 'tree_graph' in tree:\n",
    "            graph = tree['tree_graph']\n",
    "            if 'nodes' in graph:\n",
    "                nodes = graph['nodes']\n",
    "                common_explainers = set(nodes) & set(matching_explainers)\n",
    "                for explainer_name in common_explainers:\n",
    "                    bt_graph_dict[index] = tree\n",
    "                    break  # Exit the inner loop after finding a match\n",
    "   \n",
    "    return bt_graph_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50a6d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the explainer list from the API\n",
    "explainer_list = get_explainer_list()\n",
    "# Get the explainer fields from the API\n",
    "explainer_fields = get_explainer_fields()\n",
    "exp_properties_dict = get_explainer_properties(explainer_list)\n",
    "properties_dict = get_properties(explainer_fields)\n",
    "filter_properties_dict = filter_properties(exp_properties_dict, filter_properties_dict = {})\n",
    "explainer_dataset_type = get_dataset_type(exp_properties_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c7d065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Images/IntegratedGradients', '/Images/NearestNeighbours']\n",
      "{'tree_1': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict RDR for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/IntegratedGradients'], 'adj': [[1], [2], [3, 4], [], []]}}, 'tree_2': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '2a1e79cf-2ccd-47d7-96a3-768047304a85', 'Instance': 'Explanation Experience', 'description': '', 'root': '89d03d85-d7dd-4dfd-be74-1d992d5bce56', 'properties': {}, 'nodes': {'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c': {'id': 'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 108}, 'firstChild': {'Id': '7e6f46df-dd97-47dd-8c60-9e6d3f479414', 'Next': {'Id': 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b', 'Next': None}}}, '89d03d85-d7dd-4dfd-be74-1d992d5bce56': {'id': '89d03d85-d7dd-4dfd-be74-1d992d5bce56', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 0}, 'firstChild': {'Id': 'eccbcfc3-74ba-48b0-8c8a-fd8790f0300c', 'Next': None}}, '7e6f46df-dd97-47dd-8c60-9e6d3f479414': {'id': '7e6f46df-dd97-47dd-8c60-9e6d3f479414', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -324, 'y': 288}, 'params': {'Question': {'key': 'Question', 'value': 'What patterns contributed to the system prediction?'}}}, 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b': {'id': 'abc690dc-1c8e-4e45-8488-8c9fcbb4bb2b', 'Concept': 'Variant', 'Instance': 'Variant', 'description': '', 'properties': {}, 'display': {'x': 0, 'y': 264}, 'firstChild': {'Id': '98489712-951e-4685-8883-76c2bcd9e634', 'Next': {'Id': 'fad46100-dcf8-42fe-8244-39e383098d32', 'Next': None}}}, '98489712-951e-4685-8883-76c2bcd9e634': {'id': '98489712-951e-4685-8883-76c2bcd9e634', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': -132, 'y': 372}, 'params': {'target_class': {'key': 'target_class', 'value': None, 'default': None, 'range': [None, None], 'required': 'false', 'description': 'Integer denoting the desired class for the computation of the attributions. Ignore for regression models. Defaults to the predicted class of the instance.', 'type': 'number'}, 'method': {'key': 'method', 'value': 'gausslegendre', 'default': 'gausslegendre', 'range': ['gausslegendre', 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid'], 'required': 'false', 'description': \"Method for the integral approximation. The methods available are: 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid', 'gausslegendre'. Defaults to 'gausslegendre'.\", 'type': 'select'}, 'n_steps': {'key': 'n_steps', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Number of step in the path integral approximation from the baseline to the input instance. Defaults to 10.', 'type': 'number'}, 'internal_batch_size': {'key': 'internal_batch_size', 'value': 100, 'default': 100, 'range': [None, None], 'required': 'false', 'description': 'Batch size for the internal batching. Defaults to 100.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1200, 'default': 1200, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 600, 'default': 600, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}, 'fad46100-dcf8-42fe-8244-39e383098d32': {'id': 'fad46100-dcf8-42fe-8244-39e383098d32', 'Concept': 'Explanation Method', 'Instance': '/Images/NearestNeighbours', 'description': '', 'properties': {}, 'display': {'x': 120, 'y': 372}, 'params': {'no_neighbours': {'key': 'no_neighbours', 'value': 3, 'default': 3, 'range': [None, None], 'required': 'false', 'description': 'number of neighbours returned as an integer; default is 3.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1200, 'default': 1200, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 600, 'default': 600, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 720, 'camera_y': 394.5, 'camera_z': 1, 'x': -192, 'y': -108}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', 'Variant', '/Images/IntegratedGradients', '/Images/NearestNeighbours'], 'adj': [[1], [2], [3, 4], [], [5, 6], [], []]}}, 'tree_3': {'tree_json': [{'version': '0.1.0', 'scope': 'tree', 'id': '33def3ec-31a8-47c1-856c-7fd724718df2', 'Instance': 'Explanation Experience', 'description': '', 'root': '546f5cee-68b0-4b90-85be-786b9957d03a', 'properties': {}, 'nodes': {'5112868d-f790-4665-ab3e-18a36a857363': {'id': '5112868d-f790-4665-ab3e-18a36a857363', 'Concept': 'Sequence', 'Instance': 'Sequence', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 168}, 'firstChild': {'Id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Next': {'Id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Next': None}}}, '546f5cee-68b0-4b90-85be-786b9957d03a': {'id': '546f5cee-68b0-4b90-85be-786b9957d03a', 'Concept': 'Priority', 'Instance': 'Priority', 'description': '', 'properties': {}, 'display': {'x': -60, 'y': 84}, 'firstChild': {'Id': '5112868d-f790-4665-ab3e-18a36a857363', 'Next': None}}, '85b9b22e-1b0a-4a9b-81a9-83952d27271a': {'id': '85b9b22e-1b0a-4a9b-81a9-83952d27271a', 'Concept': 'User Question', 'Instance': 'User Question', 'description': '', 'properties': {}, 'display': {'x': -192, 'y': 324}, 'params': {'Question': {'key': 'Question', 'value': 'Why does the system predict category Y for image X?'}}}, '5829d6db-5011-4ad8-846a-ab8452c6be46': {'id': '5829d6db-5011-4ad8-846a-ab8452c6be46', 'Concept': 'Explanation Method', 'Instance': '/Images/IntegratedGradients', 'description': '', 'properties': {}, 'display': {'x': 60, 'y': 324}, 'params': {'output_classes': {'key': 'output_classes', 'value': '[ ]', 'default': '[ ]', 'range': [None, None], 'required': 'false', 'description': 'Array of integers representing the classes to be explained. Defaults to class 1.', 'type': 'text'}, 'top_classes': {'key': 'top_classes', 'value': 1, 'default': 1, 'range': [None, None], 'required': 'false', 'description': \"Integer representing the number of classes with the highest prediction probability to be explained. Overrides 'output_classes' if provided.\", 'type': 'number'}, 'num_features': {'key': 'num_features', 'value': 10, 'default': 10, 'range': [None, None], 'required': 'false', 'description': 'Integer representing the maximum number of features to be included in the explanation.', 'type': 'number'}, 'png_width': {'key': 'png_width', 'value': 1000, 'default': 1000, 'range': [None, None], 'required': 'false', 'description': 'Width (in pixels) of the png image containing the explanation.', 'type': 'number'}, 'png_height': {'key': 'png_height', 'value': 400, 'default': 400, 'range': [None, None], 'required': 'false', 'description': 'Height (in pixels) of the png image containing the explanation.', 'type': 'number'}}}}, 'display': {'camera_x': 937, 'camera_y': 472, 'camera_z': 1, 'x': -60, 'y': 0}}], 'tree_graph': {'nodes': ['r', 'Priority', 'Sequence', 'User Question', '/Images/IntegratedGradients'], 'adj': [[1], [2], [3, 4], [], []]}}}\n"
     ]
    }
   ],
   "source": [
    "# Function call to pass the property values marked on the form\n",
    "\n",
    "##### Need to modify the property_values based on the outcome from the form ######\n",
    "\n",
    "# example: \n",
    "property_values = {\"portability\": \"http://www.w3id.org/iSeeOnto/explainer#modelClassSpecific\",\n",
    "\"dataset_type\": \"http://www.w3id.org/iSeeOnto/explainer#image\"}\n",
    "\n",
    "bt_graph_dict = bts_with_critiques(exp_properties_dict, property_values)\n",
    "print(bt_graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a4095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
